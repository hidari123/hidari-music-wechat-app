{"version":3,"sources":["doctoc.js","lib/file.js","lib/transform.js","lib/get-html-headers.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA,ACHA;AFOA,ACHA,ACHA;AFOA,ACHA,ACHA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,ACHA,AENA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AGTA,ADGA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AFOA,AENA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\n\n\n\nvar path      =  require('path')\n  , fs        =  require('fs')\n  , minimist  =  require('minimist')\n  , file      =  require('./lib/file')\n  , transform =  require('./lib/transform')\n  , files;\n\nfunction cleanPath(path) {\n  var homeExpanded = (path.indexOf('~') === 0) ? process.env.HOME + path.substr(1) : path;\n\n  // Escape all spaces\n  return homeExpanded.replace(/\\s/g, '\\\\ ');\n}\n\nfunction transformAndSave(files, mode, maxHeaderLevel, title, notitle, entryPrefix, processAll, stdOut, updateOnly) {\n  if (processAll) {\n    console.log('--all flag is enabled. Including headers before the TOC location.')\n  }\n\n  if (updateOnly) {\n    console.log('--update-only flag is enabled. Only updating files that already have a TOC.')\n  }\n  \n  console.log('\\n==================\\n');\n\n  var transformed = files\n    .map(function (x) {\n      var content = fs.readFileSync(x.path, 'utf8')\n        , result = transform(content, mode, maxHeaderLevel, title, notitle, entryPrefix, processAll, updateOnly);\n      result.path = x.path;\n      return result;\n    });\n  var changed = transformed.filter(function (x) { return x.transformed; })\n    , unchanged = transformed.filter(function (x) { return !x.transformed; })\n    , toc = transformed.filter(function (x) { return x.toc; })\n\n  if (stdOut) {\n    toc.forEach(function (x) {\n      console.log(x.toc)\n    })\n  }\n\n  unchanged.forEach(function (x) {\n    console.log('\"%s\" is up to date', x.path);\n  });\n\n  changed.forEach(function (x) { \n    if (stdOut) {\n      console.log('==================\\n\\n\"%s\" should be updated', x.path)\n    } else {\n      console.log('\"%s\" will be updated', x.path);\n      fs.writeFileSync(x.path, x.data, 'utf8');\n    }\n  });\n}\n\nfunction printUsageAndExit(isErr) {\n\n  var outputFunc = isErr ? console.error : console.info;\n\n  outputFunc('Usage: doctoc [mode] [--entryprefix prefix] [--notitle | --title title] [--maxlevel level] [--all] [--update-only] <path> (where path is some path to a directory (e.g., .) or a file (e.g., README.md))');\n  outputFunc('\\nAvailable modes are:');\n  for (var key in modes) {\n    outputFunc('  --%s\\t%s', key, modes[key]);\n  }\n  outputFunc('Defaults to \\'' + mode + '\\'.');\n\n  process.exit(isErr ? 2 : 0);\n}\n\nvar modes = {\n    bitbucket : 'bitbucket.org'\n  , nodejs    : 'nodejs.org'\n  , github    : 'github.com'\n  , gitlab    : 'gitlab.com'\n  , ghost     : 'ghost.org'\n}\n\nvar mode = modes['github'];\n\nvar argv = minimist(process.argv.slice(2)\n    , { boolean: [ 'h', 'help', 'T', 'notitle', 's', 'stdout', 'all' , 'u', 'update-only'].concat(Object.keys(modes))\n    , string: [ 'title', 't', 'maxlevel', 'm', 'entryprefix' ]\n    , unknown: function(a) { return (a[0] == '-' ? (console.error('Unknown option(s): ' + a), printUsageAndExit(true)) : true); }\n    });\n\nif (argv.h || argv.help) {\n  printUsageAndExit();\n}\n\nfor (var key in modes) {\n  if (argv[key]) {\n    mode = modes[key];\n  }\n}\n\nvar title = argv.t || argv.title;\nvar notitle = argv.T || argv.notitle;\nvar entryPrefix = argv.entryprefix || '-';\nvar processAll = argv.all;\nvar stdOut = argv.s || argv.stdout\nvar updateOnly = argv.u || argv['update-only']\n\nvar maxHeaderLevel = argv.m || argv.maxlevel;\nif (maxHeaderLevel && isNaN(maxHeaderLevel) || maxHeaderLevel < 0) { console.error('Max. heading level specified is not a positive number: ' + maxHeaderLevel), printUsageAndExit(true); }\n\nfor (var i = 0; i < argv._.length; i++) {\n  var target = cleanPath(argv._[i])\n    , stat = fs.statSync(target)\n\n  if (stat.isDirectory()) {\n    console.log ('\\nDocToccing \"%s\" and its sub directories for %s.', target, mode);\n    files = file.findMarkdownFiles(target);\n  } else {\n    console.log ('\\nDocToccing single file \"%s\" for %s.', target, mode);\n    files = [{ path: target }];\n  }\n\n  transformAndSave(files, mode, maxHeaderLevel, title, notitle, entryPrefix, processAll, stdOut, updateOnly);\n\n  console.log('\\nEverything is OK.');\n}\n\nmodule.exports.transform = transform;\n","var path  =  require('path')\n ,  fs  =  require('fs')\n ,  _   =  require('underscore');\n\nvar markdownExts = ['.md', '.markdown'];\nvar ignoredDirs  = ['.', '..', '.git', 'node_modules'];\n\nfunction separateFilesAndDirs(fileInfos) {\n  return {\n    directories :  _(fileInfos).filter(function (x) {\n      return x.isDirectory() && !_(ignoredDirs).include(x.name);\n    }),\n    markdownFiles :  _(fileInfos).filter(function (x) { \n      return x.isFile() && _(markdownExts).include(path.extname(x.name)); \n    })\n  };\n}\n\nfunction findRec(currentPath) {\n  function getStat (entry) {\n    var target = path.join(currentPath, entry),\n      stat = fs.statSync(target);\n\n    return  _(stat).extend({ \n      name: entry,\n      path: target\n    });\n  }\n  \n  function process (fileInfos) {\n    var res = separateFilesAndDirs(fileInfos);\n    var tgts = _(res.directories).pluck('path');\n\n    if (res.markdownFiles.length > 0) \n      console.log('\\nFound %s in \"%s\"', _(res.markdownFiles).pluck('name').join(', '), currentPath);\n    else \n      console.log('\\nFound nothing in \"%s\"', currentPath);\n\n    return { \n      markdownFiles :  res.markdownFiles,\n      subdirs     :  tgts\n    };\n  }\n\n  var stats                  =  _(fs.readdirSync(currentPath)).map(getStat)\n    , res                    =  process(stats)\n    , markdownsInSubdirs     =  _(res.subdirs).map(findRec)\n    , allMarkdownsHereAndSub =  res.markdownFiles.concat(markdownsInSubdirs);\n\n  return _(allMarkdownsHereAndSub).flatten();\n}\n\n// Finds all markdown files in given directory and its sub-directories\n// @param {String  } dir - the absolute directory to search in \nexports.findMarkdownFiles = function(dir) {\n  return findRec(dir);\n};\n\n/* Example:\nconsole.log('\\033[2J'); // clear console\n\nvar res = findRec(path.join(__dirname, '..', 'samples'));\nconsole.log('Result: ', res);\n*/\n","\n\nvar _             = require('underscore')\n  , anchor        = require('anchor-markdown-header')\n  , updateSection = require('update-section')\n  , getHtmlHeaders = require('./get-html-headers')\n  , md            = require('@textlint/markdown-to-ast');\n\nvar start = '<!-- START doctoc generated TOC please keep comment here to allow auto update -->\\n' +\n            '<!-- DON\\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->'\n  , end   = '<!-- END doctoc generated TOC please keep comment here to allow auto update -->'\n  , skipTag = '<!-- DOCTOC SKIP -->';\n\n\nfunction matchesStart(line) {\n  return (/<!-- START doctoc /).test(line);\n}\n\nfunction matchesEnd(line) {\n  return (/<!-- END doctoc /).test(line);\n}\n\nfunction notNull(x) { return  x !== null; }\n\nfunction addAnchor(mode, header) {\n  header.anchor = anchor(header.name, mode, header.instance);\n  return header;\n}\n\nfunction isString(y) {\n  return typeof y === 'string';\n}\n\n\nfunction getMarkdownHeaders (lines, maxHeaderLevel) {\n  function extractText (header) {\n    return header.children\n      .map(function (x) {\n        if (x.type === md.Syntax.Link) {\n          return extractText(x);\n        }\n        else if (x.type === md.Syntax.Image) {\n          // Images (at least on GitHub, untested elsewhere) are given a hyphen\n          // in the slug. We can achieve this behavior by adding an '*' to the\n          // TOC entry. Think of it as a \"magic char\" that represents the iamge.\n          return '*';\n        }\n        else {\n          return x.raw;\n        }\n      })\n      .join('')\n  }\n\n  return md.parse(lines.join('\\n')).children\n    .filter(function (x) {\n      return x.type === md.Syntax.Header;\n    })\n    .map(function (x) {\n      return !maxHeaderLevel || x.depth <= maxHeaderLevel\n        ? { rank :  x.depth\n          , name :  extractText(x)\n          , line :  x.loc.start.line\n          }\n        : null;\n    })\n    .filter(notNull)\n}\n\nfunction countHeaders (headers) {\n  var instances = {};\n\n  for (var i = 0; i < headers.length; i++) {\n    var header = headers[i];\n    var name = header.name;\n\n    if (Object.prototype.hasOwnProperty.call(instances, name)) {\n      // `instances.hasOwnProperty(name)` fails when thereâ€™s an instance named \"hasOwnProperty\".\n      instances[name]++;\n    } else {\n      instances[name] = 0;\n    }\n\n    header.instance = instances[name];\n  }\n\n  return headers;\n}\n\nfunction getLinesToToc (lines, currentToc, info, processAll) {\n  if (processAll || !currentToc) return lines;\n\n  var tocableStart = 0;\n\n  // when updating an existing toc, we only take the headers into account\n  // that are below the existing toc\n  if (info.hasEnd) tocableStart = info.endIdx + 1;\n\n  return lines.slice(tocableStart);\n}\n\n// Use document context as well as command line args to infer the title\nfunction determineTitle(title, notitle, lines, info) {\n  var defaultTitle = '**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*';\n\n  if (notitle) return '';\n  if (title) return title;\n  return info.hasStart ? lines[info.startIdx + 2] : defaultTitle;\n}\n\nexports = module.exports = function transform(content, mode, maxHeaderLevel, title, notitle, entryPrefix, processAll, updateOnly) {\n  if (content.indexOf(skipTag) !== -1) return { transformed: false };\n\n  mode = mode || 'github.com';\n  entryPrefix = entryPrefix || '-';\n\n  // only limit *HTML* headings by default\n  var maxHeaderLevelHtml = maxHeaderLevel || 4;\n\n  var lines = content.split('\\n')\n    , info = updateSection.parse(lines, matchesStart, matchesEnd)\n\n  if (!info.hasStart && updateOnly) {\n    return { transformed: false };\n  }\n\n  var inferredTitle = determineTitle(title, notitle, lines, info);\n\n  var titleSeparator = inferredTitle ? '\\n\\n' : '\\n';\n\n  var currentToc = info.hasStart && lines.slice(info.startIdx, info.endIdx + 1).join('\\n')\n    , linesToToc = getLinesToToc(lines, currentToc, info, processAll);\n\n  var headers = getMarkdownHeaders(linesToToc, maxHeaderLevel)\n    .concat(getHtmlHeaders(linesToToc, maxHeaderLevelHtml))\n\n  headers.sort(function (a, b) {\n    return a.line - b.line;\n  });\n\n  var allHeaders    =  countHeaders(headers)\n    , lowestRank    =  _(allHeaders).chain().pluck('rank').min().value()\n    , linkedHeaders =  _(allHeaders).map(addAnchor.bind(null, mode));\n\n  if (linkedHeaders.length === 0) return { transformed: false };\n\n  // 4 spaces required for proper indention on Bitbucket and GitLab\n  var indentation = (mode === 'bitbucket.org' || mode === 'gitlab.com') ? '    ' : '  ';\n\n  var toc =\n      inferredTitle\n    + titleSeparator\n    + linkedHeaders\n        .map(function (x) {\n          var indent = _(_.range(x.rank - lowestRank))\n            .reduce(function (acc, x) { return acc + indentation; }, '');\n\n          return indent + entryPrefix + ' ' + x.anchor;\n        })\n        .join('\\n')\n    + '\\n';\n\n  var wrappedToc =  start + '\\n' + toc + '\\n' + end;\n\n  if (currentToc === toc) return { transformed: false };\n\n  var data = updateSection(lines.join('\\n'), wrappedToc, matchesStart, matchesEnd, true);\n  return { transformed : true, data : data, toc: toc, wrappedToc: wrappedToc };\n};\n\nexports.start = start;\nexports.end = end;\n","\n\nvar htmlparser = require('htmlparser2')\n  , md         = require('@textlint/markdown-to-ast');\n\nfunction addLinenos(lines, headers) {\n  var current = 0, line;\n\n  return headers.map(function (x) {\n    for (var lineno = current; lineno < lines.length; lineno++) {\n      line = lines[lineno];\n      if (new RegExp(x.text[0]).test(line)) {\n        current = lineno;\n        x.line = lineno;\n        x.name = x.text.join('');\n        return x\n      }\n    }\n\n    // in case we didn't find a matching line, which is odd,\n    // we'll have to assume it's right on the next line\n    x.line = ++current;\n    x.name = x.text.join('');\n    return x\n  })\n}\n\nfunction rankify(headers, max) {\n  return headers\n    .map(function (x) {\n      x.rank = parseInt(x.tag.slice(1), 10);\n      return x;\n    })\n    .filter(function (x) {\n      return x.rank <= max;\n    })\n}\n\nvar go = module.exports = function (lines, maxHeaderLevel) {\n  var source = md.parse(lines.join('\\n'))\n    .children\n    .filter(function(node) {\n      return node.type === md.Syntax.HtmlBlock || node.type === md.Syntax.Html;\n    })\n    .map(function (node) {\n      return node.raw;\n    })\n    .join('\\n');\n\n  //var headers = [], grabbing = null, text = [];\n  var headers = [], grabbing = [], text = [];\n\n  var parser = new htmlparser.Parser({\n    onopentag: function (name, attr) {\n      // Short circuit if we're already inside a pre\n      if (grabbing[grabbing.length - 1] === 'pre') return;\n\n      if (name === 'pre' || (/h\\d/).test(name)) {\n        grabbing.push(name);\n      }\n    },\n    ontext: function (text_) {\n      // Explicitly skip pre tags, and implicitly skip all others\n      if (grabbing.length === 0 ||\n          grabbing[grabbing.length - 1] === 'pre') return;\n\n      text.push(text_);\n    },\n    onclosetag: function (name) {\n      if (grabbing.length === 0) return;\n      if (grabbing[grabbing.length - 1] === name) {\n        var tag = grabbing.pop();\n        headers.push({ text: text, tag: tag });\n        text = [];\n      }\n    }\n  },\n  { decodeEntities: true })\n\n  parser.write(source);\n  parser.end();\n\n  headers = addLinenos(lines, headers)\n  // consider anything past h4 to small to warrant a link, may be made configurable in the future\n  headers = rankify(headers, maxHeaderLevel);\n  return headers;\n}\n"]}